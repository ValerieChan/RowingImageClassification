{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code based on:\n",
    "#https://www.r-bloggers.com/r-vs-python-image-classification-with-keras/\n",
    "#Thanks!!\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ( Conv2D, Dense, LeakyReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten)\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.now()\n",
    "\n",
    "\n",
    "#image categories\n",
    "image_list = [\"Rowing\", \"Erg\", \"Other\"]\n",
    "\n",
    "#number of output classes\n",
    "output_n = len(image_list)\n",
    "\n",
    "#image size to scale down to\n",
    "img_width = 20\n",
    "img_height = 20\n",
    "target_size = (img_width, img_height)\n",
    "\n",
    "#image rgb channel number\n",
    "channels = 3\n",
    "\n",
    "#path\n",
    "path = \"data/\"\n",
    "train_image_files_path = path + \"Training\"\n",
    "valid_image_files_path = path + \"Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input data augmentation/modification\n",
    "# training images\n",
    "train_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "# validation images\n",
    "valid_data_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 138 images belonging to 3 classes.\n",
      "Found 27 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "# training images\n",
    "train_image_array_gen = train_data_gen.flow_from_directory(train_image_files_path, target_size = target_size,\n",
    "                                                           classes = image_list, class_mode = 'categorical',\n",
    "                                                           seed = 42)\n",
    "# validation images\n",
    "valid_image_array_gen = valid_data_gen.flow_from_directory(valid_image_files_path, target_size = target_size,\n",
    "                                                           classes = image_list, class_mode = 'categorical',\n",
    "                                                           seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model definition\n",
    "# number of training samples\n",
    "train_samples = train_image_array_gen.n\n",
    "\n",
    "# number of validation samples\n",
    "valid_samples = valid_image_array_gen.n\n",
    "\n",
    "# define batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers\n",
    "# input layer\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', input_shape = (img_width, img_height, channels), activation = 'relu'))\n",
    "# hiddel conv layer\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3), padding = 'same'))\n",
    "model.add(LeakyReLU(.5))\n",
    "model.add(BatchNormalization())\n",
    "# using max pooling\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# randomly switch off 25% of the nodes per epoch step to avoid overfitting\n",
    "model.add(Dropout(0.25))\n",
    "# flatten max filtered output into feature vector\n",
    "model.add(Flatten())\n",
    "# output features onto a dense layer\n",
    "model.add(Dense(units = 100, activation = 'relu'))\n",
    "# randomly switch off 25% of the nodes per epoch step to avoid overfitting\n",
    "model.add(Dropout(.5))\n",
    "# output layer with the number of units equal to the number of categories\n",
    "model.add(Dense(units = output_n, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'],  optimizer = RMSprop(lr = 1e-4, decay = 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/20\n",
      " - 13s - loss: 1.8906 - acc: 0.3667 - val_loss: 1.9154 - val_acc: 0.1481\n",
      "Epoch 2/20\n",
      " - 15s - loss: 1.0839 - acc: 0.6406 - val_loss: 2.1088 - val_acc: 0.1111\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1.0441 - acc: 0.5651 - val_loss: 2.2366 - val_acc: 0.0741\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.6763 - acc: 0.7040 - val_loss: 2.5080 - val_acc: 0.0741\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.6716 - acc: 0.7421 - val_loss: 2.3674 - val_acc: 0.0741\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.7831 - acc: 0.7315 - val_loss: 2.2129 - val_acc: 0.1111\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1.0138 - acc: 0.6027 - val_loss: 1.9805 - val_acc: 0.1111\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.5171 - acc: 0.7497 - val_loss: 1.9784 - val_acc: 0.0741\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.9695 - acc: 0.6571 - val_loss: 1.6114 - val_acc: 0.1852\n",
      "Epoch 10/20\n",
      " - 14s - loss: 0.5207 - acc: 0.8125 - val_loss: 1.8084 - val_acc: 0.1852\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.6361 - acc: 0.7584 - val_loss: 1.8232 - val_acc: 0.1481\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.6378 - acc: 0.7284 - val_loss: 1.9770 - val_acc: 0.0741\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.4226 - acc: 0.8317 - val_loss: 1.8907 - val_acc: 0.0741\n",
      "Epoch 14/20\n",
      " - 14s - loss: 0.6223 - acc: 0.7656 - val_loss: 1.8839 - val_acc: 0.1481\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.3852 - acc: 0.8535 - val_loss: 1.7451 - val_acc: 0.2222\n",
      "Epoch 16/20\n",
      " - 13s - loss: 0.4483 - acc: 0.8479 - val_loss: 1.9007 - val_acc: 0.1852\n",
      "Epoch 17/20\n",
      " - 17s - loss: 0.6643 - acc: 0.7422 - val_loss: 1.5802 - val_acc: 0.2593\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.3203 - acc: 0.8776 - val_loss: 1.6382 - val_acc: 0.1852\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.3272 - acc: 0.8642 - val_loss: 1.5917 - val_acc: 0.2222\n",
      "Epoch 20/20\n",
      " - 15s - loss: 0.3492 - acc: 0.8594 - val_loss: 1.3905 - val_acc: 0.3704\n"
     ]
    }
   ],
   "source": [
    "callback_1 = [\n",
    "    # save best model after every epoch\n",
    "    ModelCheckpoint(\"rowing_checkpoints.h5\", save_best_only = True),\n",
    "    # only needed for visualising with TensorBoard\n",
    "    TensorBoard(log_dir = \"rowing_logs\")\n",
    "  ]\n",
    "\n",
    "# train the model\n",
    "hist = model.fit_generator(\n",
    "  # training data\n",
    "  train_image_array_gen,\n",
    "\n",
    "  # epochs\n",
    "  steps_per_epoch = train_samples // batch_size, \n",
    "  epochs = epochs, \n",
    "\n",
    "  # validation data\n",
    "  validation_data = valid_image_array_gen,\n",
    "  #validation_steps = valid_samples // batch_size,\n",
    "\n",
    "  # print progress\n",
    "  verbose = 2,\n",
    "  callbacks=callback_1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = {'acc': hist.history['acc'][epochs - 1], 'val_acc': hist.history['val_acc'][epochs - 1], 'elapsed_time': (dt.now() - start).seconds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.859375, 'val_acc': 0.37037035822868347, 'elapsed_time': 253}\n"
     ]
    }
   ],
   "source": [
    "print(df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model_sample.py\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(20, 20))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify (Path):\n",
    "# image path\n",
    "    img_path = Path#'Data/Test/Rowing/IMG_0088.jpg'    # rowing\n",
    "#img_path = '/media/data/dogscats/test1/19.jpg'      # erg\n",
    "\n",
    "# load a single image\n",
    "    new_image = load_image(img_path)\n",
    "\n",
    "# check prediction\n",
    "    pred = model.predict(new_image)\n",
    "\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69822776 0.18845087 0.11332136]]\n",
      "[[0.02419115 0.96180993 0.01399886]]\n",
      "[[0.3906852  0.28799596 0.32131884]]\n",
      "[[0.7196516  0.24432665 0.03602175]]\n"
     ]
    }
   ],
   "source": [
    "classify('Data/Test/Rowing/IMG_0088.jpg' )\n",
    "classify('Data/Test/Erg/IMG_0073.jpg' )\n",
    "classify('Data/Test/Other/IMG_0015.jpg' )\n",
    "classify('Data/Test/Other/simpsons.jpg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'Data/Test/Rowing/.DS_Store/IMG_0088.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-21504e0380ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3703b11611c5>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(Path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load a single image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# check prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e7786d893837>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(img_path, show)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# (height, width, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    360\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    361\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'Data/Test/Rowing/.DS_Store/IMG_0088.JPG'"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in image_list:\n",
    "    \n",
    "    path = 'Data/Test/'+item    \n",
    "    #image_list    \n",
    "\n",
    "    listing = os.listdir(path)    \n",
    "    for file in listing:\n",
    "        path = path+'/'+file\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "        classify(path)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
